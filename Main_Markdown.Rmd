---
title: "Main_Markdown"
author: "Tobias Gradinger"
date: "2024-01-17"
output: html_document
---
Find the tutorial here: https://choishingwan.github.io/PRS-Tutorial/target/

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r SETUP-Packages, eval=T, message=F}
library(data.table)
library(dplyr)
```

# QC of base data

## Heritability check
Chip-heritability estimate should be h^2 snp > .05
Methods for estimating heritability:
- LD Score Regression (LDSC) (Paper: LD Score Regression Distinguishes Confounding from Polygenicity in Genome-Wide Association Studies, Brendan 2015)
-- Variants which are in linkage disequilibrium with a causal variant show elevated test statistics (OR/Beta/etc.) proportional to the linkage disequilibrium (measured ad r^2)
-- Cryptic relatedness
--- subjects are more related with each other than expected
-- Population stratification (syn: population structure, genetic structure)
--- systemic difference of allele frequency between subpopulations. E.g. through non-random mating. Leads, among other things, to a reduction of
--- heterozygosity (Mutter und Vater Allele sind im Schnitt ähnlicher -> weniger Allele sind heterozygot)
---- Measured with Wright's F-statistics (Fst = 1 - (heterozygote Allel-Frequenz in der Subpopulation / heterozygote Allel-Frequenz in der Gesamtpopulation))
---- if it is 0 then they are identical suggesting no structure
will not correlate with the LD Score

## Effect allele
It is important to know which allele is the effect allele and which is the non-effect allele for PRS association results to be in the correct direction.

## File transfer
Integrity of the file after several transfers can be checked with a hash.

```{bash, eval=F}
#bash chunks do not work for whatever reason - execute in terminal by using strg+alt+Enter
#creates a hash which can be compared to the hash given by the provider - if identical data should not be compromised
md5sum Height.gwas.txt.gz
```

## Genome build
Base and target data must be on the same genome build. If not tools such as LiftOver can be used to synchronize them.

## Standard QWAS QC
Standardfilter sind MAF > 1% und INFO (imputation information score) < 0.8
```{r READ Data}
dat <- fread("Height.gwas.txt.gz")
```

```{r DATA Quality Control I Info and MAF filtering}
# Filter out SNPs with too much imputation (INFO > 0.8) and too low of a minor allele freq (MAF > 0.01))
result <- dat[INFO > 0.8 & MAF > 0.01]
```

```{r WRITE Data Heigth.gz}
# Output the gz file after the Filtering
fwrite(result, "Height.gz", sep="\t")
```

## Mismatching SNPs
Strand-flipping will be performed in the target data.

## Duplicate SNPs
Can happen if an error occurred in the generation of the base data. Have to be removed.
```{r Data Quality control II Remove duplicate SNPs}
# Find number of duplicate SNPs
result %>% 
  count(SNP, name = "count") %>% 
  filter (count>1) %>% 
  length()

# Remove duplicates from the dataset
result.clean <-
  result %>% 
  distinct()
```

```{r WRITE DATA Height.nodup.gz}
fwrite(result.clean, "Height.nodup.gz", sep="\t")
```

## Ambigous SNPs
Base und target data sind manchmal mit unterschiedlichen genotyping chips generiert worden. Wenn jetzt unklar ist, ob der + oder der - Strang verwendet wurde, ist es unmöglich ambigous SNPs zu pairen (A/T, T/A, G/C, C/G) 
```{r Data Quality control III Filter out ambigous SNPs}
result.clean<-
result.clean %>% 
  filter(!(A1 == "A" & A2 == "T" |
           A1 == "T" & A2 == "A" |
           A1 == "G" & A2 == "C" |
           A1 == "C" & A2 == "G"))
```

```{r WRITE DATA Height.QC.gz}
fwrite(result.clean, "Height.QC.gz", sep="\t")
```

# Target data

## Control the hashes
```{bash, eval=F}
md5sum EUR.bed
md5sum EUR.bim
md5sum EUR.cov
md5sum EUR.fam
md5sum EUR.height
```

## MAF, Hardy-Weinberg, Imputes, Missings 
```{bash, eval=F}
# the target data is cleaned up based on certain criteria (see tutorial or paper)
plink \
    --bfile EUR \
    --maf 0.01 \
    --hwe 1e-6 \
    --geno 0.01 \
    --mind 0.01 \
    --write-snplist \
    --make-just-fam \
    --out EUR.QC
```

## Pruning
```{bash, eval=F}
# Pruning is done, creates two files: EUR.QC.prune.in (r^2>0.25) and EUR.QC.prune.out
plink \
    --bfile EUR \
    --keep EUR.QC.fam \
    --extract EUR.QC.snplist \
    --indep-pairwise 200 50 0.25 \
    --out EUR.QC
```

## Heterozygosity
```{bash, eval=F}
# F Score for heterozygosity is calculated
plink \
    --bfile EUR \
    --extract EUR.QC.prune.in \
    --keep EUR.QC.fam \
    --het \
    --out EUR.QC
```

```{r DATA filtering based on F Score}
# Read in file
dat <- fread("EUR.QC.het")
# Get samples with F coefficient within 3 SD of the population mean
valid <-
  dat %>% 
  filter(F<=mean(F)+3*sd(F) & F>=mean(F)-3*sd(F))
# print FID and IID for valid samples
fwrite(valid[,c("FID","IID")], "EUR.valid.sample", sep="\t") 
```

## Mismatching SNPs (between base and target data)
```{r read DATA EUR.bim Height.Qc.gz EUR.QC.snplist}
# Read in bim file 
bim <- fread("EUR.bim") %>%
    # Note: . represents the output from previous step
    # The syntax here means, setnames of the data read from
    # the bim file, and replace the original column names by 
    # the new names
    setnames(., colnames(.), c("CHR", "SNP", "CM", "BP", "B.A1", "B.A2")) %>%
    # And immediately change the alleles to upper cases
    .[,c("B.A1","B.A2"):=list(toupper(B.A1), toupper(B.A2))]
# Read in summary statistic data aka the base data (GWAS)
height <- fread("Height.QC.gz") %>%
    # And immediately change the alleles to upper cases
    .[,c("A1","A2"):=list(toupper(A1), toupper(A2))]
# Read in QCed SNPs
qc <- fread("EUR.QC.snplist", header=F)
```

```{r merge base and target}
# Merge summary statistic with target
info <- merge(bim, height, by=c("SNP", "CHR", "BP")) %>%
    # And filter out QCed SNPs
    .[SNP %in% qc[,V1]]

# Function for calculating the complementary allele
complement <- function(x){
    switch (x,
        "A" = "T",
        "C" = "G",
        "T" = "A",
        "G" = "C",
        return(NA)
    )
} 
# Get SNPs that have the same alleles across base and target
info.match <- info[A1 == B.A1 & A2 == B.A2, SNP]
# Identify SNPs that are complementary between base and target
com.snps <- info[sapply(B.A1, complement) == A1 &
                    sapply(B.A2, complement) == A2, SNP]
# Now update the bim file
bim[SNP %in% com.snps, c("B.A1", "B.A2") :=
        list(sapply(B.A1, complement),
            sapply(B.A2, complement))]
```

```{r}
# identify SNPs that need recoding
recode.snps <- info[B.A1==A2 & B.A2==A1, SNP]
# Update the bim file
bim[SNP %in% recode.snps, c("B.A1", "B.A2") :=
        list(B.A2, B.A1)]

# identify SNPs that need recoding & complement
com.recode <- info[sapply(B.A1, complement) == A2 &
                    sapply(B.A2, complement) == A1, SNP]
# Now update the bim file
bim[SNP %in% com.recode, c("B.A1", "B.A2") :=
        list(sapply(B.A2, complement),
            sapply(B.A1, complement))]
# Write the updated bim file
fwrite(bim[,c("SNP", "B.A1")], "EUR.a1", col.names=F, sep="\t")
```

```{r Still different allele in base and target}
mismatch <- bim[!(SNP %in% info.match |
                    SNP %in% com.snps |
                    SNP %in% recode.snps |
                    SNP %in% com.recode), SNP]
write.table(mismatch, "EUR.mismatch", quote=F, row.names=F, col.names=F)
```

## Duplicate SNPs
Not necessary in this tutorial as the target data is simulated data.

##Sex check 
Use plink to check whether the sex phenotype corresponds to the gonosome genotype. X-Chromosome homozygosity estimate <0.2 is considered female >0.8 is considered male.
```{bash, eval=F}
# generating the F-statistic using plink
plink \
    --bfile EUR \
    --extract EUR.QC.prune.in \
    --keep EUR.valid.sample \
    --check-sex \
    --out EUR.QC
```

```{r}
# Read in file
valid <- fread("EUR.valid.sample")
dat <- fread("EUR.QC.sexcheck")[FID%in%valid$FID]
fwrite(dat[STATUS=="OK",c("FID","IID")], "EUR.QC.valid", sep="\t") 
```

## Sample overlap
Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap).

## Relatedness
Closely related individuals in the target data may lead to overfitted results, limiting the generalisability of the results.

Before calculating the relatedness, pruning should be performed (see here). Individuals that have a first or second degree relative in the sample (π > 0.125) can be removed with the following command:

```{bash, eval=F}
plink \
    --bfile EUR \
    --extract EUR.QC.prune.in \
    --keep EUR.QC.valid \
    --rel-cutoff 0.125 \
    --out EUR.QC
```

## Generate final file with all the QC steps applied

```{bash, eval=F}
plink \
    --bfile EUR \
    --make-bed \
    --keep EUR.QC.rel.id \
    --out EUR.QC \
    --extract EUR.QC.snplist \
    --exclude EUR.mismatch \
    --a1-allele EUR.a1
```

# End of Quality control

# Programs and methods to calculate and analyze the Polygenic risk scores

## Plink

## LDpred-2

```{r SETUP}
library(bigsnpr)
options(bigstatsr.check.parallel.blas = FALSE)
options(default.nproc.blas = NULL)
```

### Read the data
Datafiles from the previous GWAS steps.
```{r DATA READ}
phenotype <- fread("EUR.height")
covariate <- fread("EUR.cov")
pcs <- fread("EUR.eigenvec")
# rename columns
colnames(pcs) <- c("FID","IID", paste0("PC",1:6))
# generate required table
pheno <- merge(phenotype, covariate) %>%
    merge(., pcs)
```

### Obtain HapMap3 SNPs
Downloading from the web did not work. Downloaded manually and put in the WordkingD.
```{r DATA READ}
info <- readRDS("map.rds")
```

### Load and transform the summary statistic file
```{r}
# Read in the summary statistic file
sumstats <- bigreadr::fread2("Height.QC.gz") 
# LDpred 2 require the header to follow the exact naming
names(sumstats) <-
    c("chr",
    "pos",
    "rsid",
    "a1",
    "a0",
    "n_eff",
    "beta_se",
    "p",
    "OR",
    "INFO",
    "MAF")
# Transform the OR into log(OR)
sumstats$beta <- log(sumstats$OR)
# Filter out hapmap SNPs
sumstats <- sumstats[sumstats$rsid%in% info$rsid,]
```

### CONTINUE HERE Calculate the LD matrix

```{r}
# Get maximum amount of cores
NCORES <- nb_cores()
# Open a temporary file
tmp <- tempfile(tmpdir = "tmp-data")
on.exit(file.remove(paste0(tmp, ".sbk")), add = TRUE)
# Initialize variables for storing the LD score and LD matrix
corr <- NULL
ld <- NULL
# We want to know the ordering of samples in the bed file 
fam.order <- NULL
# preprocess the bed file (only need to do once for each data set)
snp_readBed("EUR.QC.bed")
# now attach the genotype object
obj.bigSNP <- snp_attach("EUR.QC.rds")
# extract the SNP information from the genotype
map <- obj.bigSNP$map[-3]
names(map) <- c("chr", "rsid", "pos", "a1", "a0")
# perform SNP matching
info_snp <- snp_match(sumstats, map)
# Assign the genotype to a variable for easier downstream analysis
genotype <- obj.bigSNP$genotypes
# Rename the data structures
CHR <- map$chr
POS <- map$pos
# get the CM information from 1000 Genome
# will download the 1000G file to the current directory (".")
POS2 <- snp_asGeneticPos(CHR, POS, dir = ".")
# calculate LD
for (chr in 1:22) {
    # Extract SNPs that are included in the chromosome
    ind.chr <- which(info_snp$chr == chr)
    ind.chr2 <- info_snp$`_NUM_ID_`[ind.chr]
    # Calculate the LD
    corr0 <- snp_cor(
            genotype,
            ind.col = ind.chr2,
            ncores = NCORES,
            infos.pos = POS2[ind.chr2],
            size = 3 / 1000
        )
    if (chr == 1) {
        ld <- Matrix::colSums(corr0^2)
        corr <- as_SFBM(corr0, tmp)
    } else {
        ld <- c(ld, Matrix::colSums(corr0^2))
        corr$add_columns(corr0, nrow(corr))
    }
}
# We assume the fam order is the same across different chromosomes
fam.order <- as.data.table(obj.bigSNP$fam)
# Rename fam order
setnames(fam.order,
        c("family.ID", "sample.ID"),
        c("FID", "IID"))
```

### Perform LD score regression

```{r}
df_beta <- info_snp[,c("beta", "beta_se", "n_eff", "_NUM_ID_")]
ldsc <- snp_ldsc(   ld, 
                    length(ld), 
                    chi2 = (df_beta$beta / df_beta$beta_se)^2,
                    sample_size = df_beta$n_eff, 
                    blocks = NULL)
h2_est <- ldsc[["h2"]]
```

### Calculate the null R2

```{r}
# Reformat the phenotype file such that y is of the same order as the 
# sample ordering in the genotype file
y <- pheno[fam.order, on = c("FID", "IID")]
# Calculate the null R2
# use glm for binary trait 
# (will also need the fmsb package to calculate the pseudo R2)
null.model <- paste("PC", 1:6, sep = "", collapse = "+") %>%
    paste0("Height~Sex+", .) %>%
    as.formula %>%
    lm(., data = y) %>%
    summary
null.r2 <- null.model$r.squared
```




